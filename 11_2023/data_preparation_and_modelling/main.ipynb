{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1479c2ef-5df8-41d9-9347-8515157629a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2a185b60-b5af-4b3e-8ec8-8ca1afbba51d",
   "metadata": {},
   "source": [
    "## preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f6ca053b-7353-42ba-9134-c99f55bcedeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "data_1 = pd.read_csv('bina_az_02102023.csv')\n",
    "data_2 = pd.read_csv('bina_az_new.csv')\n",
    "data_3 = pd.read_csv('bina_az_old.csv')\n",
    "data_4 = pd.read_csv('bina_az_25102023.csv')\n",
    "frames = pd.concat([data_1, data_2, data_3,data_4]).drop_duplicates().dropna()\n",
    "frames['is_near_metro'] = (frames['description'].str.contains('m\\.', case=False) | frames['description'].str.contains('metro',case=False)).astype(int)\n",
    "frames = frames[frames['seller_type'] != 'seller_type']\n",
    "frames[['flat', 'total_flat']] = frames['flat_number'].str.split(' / ', expand=True).astype(int)\n",
    "remove_non_numeric_and_convert_to_float = lambda value: float(re.sub(r'[^\\d.]', '', value)) if value else None\n",
    "frames['area_converted'] = frames['area'].apply(remove_non_numeric_and_convert_to_float)\n",
    "frames['room_count'] = frames['room_count'].astype(int)\n",
    "frames['documents_encoded'] = frames['documents'].map({'var': 1, 'yoxdur': 0})\n",
    "frames['is_repair_encoded'] = frames['is_repair'].map({'var': 1, 'yoxdur': 0})\n",
    "frames['seller_type_encoded'] = frames['seller_type'].map({'vasitəçi (agent)': 0, 'mülkiyyətçi': 1})\n",
    "frames['category_encoded'] = frames['category'].map({'Yeni tikili': 0, 'Köhnə tikili': 1})\n",
    "frames['price'] = frames['price'].str.replace(' ', '').astype(int)\n",
    "frames = frames[['is_near_metro', \n",
    "                 'seller_type_encoded', \n",
    "                 'flat', \n",
    "                 'total_flat', \n",
    "                 'room_count',\n",
    "                 'area_converted', \n",
    "                 'category_encoded',\n",
    "                 'documents_encoded',\n",
    "                 'is_repair_encoded', \n",
    "                 'price']].drop_duplicates(ignore_index=True)\n",
    "# frames.to_excel('frames.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f655ca2b-39ad-4551-9335-942d1912d9f8",
   "metadata": {},
   "source": [
    "## XGBOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "07527bc7-f725-48c2-af57-5d26ef3b25e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model performance metrics\n",
      "-----------------------\n",
      "R-squared: 0.71\n",
      "Root Mean Squared Error: 94855.12\n",
      "Mean Absolute Error: 47748.10\n",
      "-----------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['xgb.pkl']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import warnings\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "data = frames\n",
    "X = data.drop(columns=['price'])\n",
    "y = data['price']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "model = xgb.XGBRegressor(\n",
    "    learning_rate=0.1,\n",
    "    n_estimators=100,\n",
    "    max_depth=3,\n",
    "    objective='reg:squarederror'\n",
    ")\n",
    "model.fit(X_train_scaled, y_train)\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "print(\"Model performance metrics\")\n",
    "print(\"-----------------------\")\n",
    "print(f\"R-squared: {r2:.2f}\")\n",
    "print(f\"Root Mean Squared Error: {rmse:.2f}\")\n",
    "print(f\"Mean Absolute Error: {mae:.2f}\")\n",
    "print(\"-----------------------\")\n",
    "joblib.dump(model, 'xgb.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db0e47c6-f40a-49bf-ba7c-b14636ee532e",
   "metadata": {},
   "source": [
    "## Grid Search RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "239384cd-3467-4f57-911a-450a4eab63a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'max_depth': 30, 'min_samples_leaf': 4, 'min_samples_split': 5, 'n_estimators': 200}\n",
      "R-squared: 0.738799711229776\n",
      "Root Mean Squared Error (RMSE): 89502.17958782492\n",
      "Mean Absolute Error (MAE): 42727.429187055845\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "import numpy as np\n",
    "data = frames\n",
    "X = data.drop(columns=['price'])\n",
    "y = data['price']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "rf_model = RandomForestRegressor()\n",
    "grid_search = GridSearchCV(estimator=rf_model, param_grid=param_grid, scoring='neg_mean_squared_error', cv=5)\n",
    "grid_search.fit(X_train, y_train)\n",
    "best_params = grid_search.best_params_\n",
    "best_model = grid_search.best_estimator_\n",
    "predictions = best_model.predict(X_test)\n",
    "print(\"Best Hyperparameters:\", best_params)\n",
    "r_squared = r2_score(y_test, predictions)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, predictions))\n",
    "mae = mean_absolute_error(y_test, predictions)\n",
    "print(\"R-squared:\", r_squared)\n",
    "print(\"Root Mean Squared Error (RMSE):\", rmse)\n",
    "print(\"Mean Absolute Error (MAE):\", mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcede46c-cb58-43f1-b985-f2a7ad116256",
   "metadata": {},
   "source": [
    "## Grid search for XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "80984780-b2a0-4057-9425-c18a4f0026fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 100, 'subsample': 0.9}\n",
      "R-squared: 0.7077243215163627\n",
      "Root Mean Squared Error (RMSE): 94676.70258377517\n",
      "Mean Absolute Error (MAE): 47888.042196584305\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "import numpy as np\n",
    "data = frames\n",
    "X = data.drop(columns=['price'])\n",
    "y = data['price']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [3, 4, 5],  \n",
    "    'learning_rate': [0.01, 0.1, 0.2],  \n",
    "    'subsample': [0.8, 0.9, 1.0], \n",
    "}\n",
    "xgb_model = XGBRegressor()  \n",
    "grid_search = GridSearchCV(estimator=xgb_model, param_grid=param_grid, scoring='neg_mean_squared_error', cv=5)\n",
    "grid_search.fit(X_train, y_train)\n",
    "best_params = grid_search.best_params_\n",
    "best_model = grid_search.best_estimator_\n",
    "predictions = best_model.predict(X_test)\n",
    "print(\"Best Hyperparameters:\", best_params)\n",
    "r_squared = r2_score(y_test, predictions)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, predictions))\n",
    "mae = mean_absolute_error(y_test, predictions)\n",
    "print(\"R-squared:\", r_squared)\n",
    "print(\"Root Mean Squared Error (RMSE):\", rmse)\n",
    "print(\"Mean Absolute Error (MAE):\", mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5642a81d-6999-4887-92c3-4fe01e37e415",
   "metadata": {},
   "source": [
    "## Ensemble methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "81e0ec6b-9687-4c82-a27a-0a09a465e60f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble Model Performance Metrics\n",
      "-----------------------\n",
      "R-squared: 0.75\n",
      "Root Mean Squared Error: 88404.88\n",
      "Mean Absolute Error: 43143.62\n",
      "-----------------------\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "import joblib\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import xgboost as xgb\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "data = frames\n",
    "X = data.drop(columns=['price'])\n",
    "y = data['price']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train_scaled, y_train)\n",
    "xgb_model = xgb.XGBRegressor(\n",
    "    learning_rate=0.1,\n",
    "    n_estimators=100,\n",
    "    max_depth=3,\n",
    "    objective='reg:squarederror'\n",
    ")\n",
    "xgb_model.fit(X_train_scaled, y_train)\n",
    "rf_predictions = rf_model.predict(X_test_scaled)\n",
    "xgb_predictions = xgb_model.predict(X_test_scaled)\n",
    "ensemble_predictions = (rf_predictions + xgb_predictions) / 2\n",
    "ensemble_r2 = r2_score(y_test, ensemble_predictions)\n",
    "ensemble_rmse = mean_squared_error(y_test, ensemble_predictions, squared=False)\n",
    "ensemble_mae = mean_absolute_error(y_test, ensemble_predictions)\n",
    "print(\"Ensemble Model Performance Metrics\")\n",
    "print(\"-----------------------\")\n",
    "print(f\"R-squared: {ensemble_r2:.2f}\")\n",
    "print(f\"Root Mean Squared Error: {ensemble_rmse:.2f}\")\n",
    "print(f\"Mean Absolute Error: {ensemble_mae:.2f}\")\n",
    "print(\"-----------------------\")\n",
    "# joblib.dump(rf_model, 'random_forest.pkl')\n",
    "# joblib.dump(xgb_model, 'xgboost.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1be878a-b204-4940-bf44-5496397d970d",
   "metadata": {},
   "source": [
    "## Stacking method for ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "97593f47-b08c-4924-8665-3aeaa9f7d02f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble Model Performance Metrics\n",
      "-----------------------\n",
      "R-squared: 0.75\n",
      "Root Mean Squared Error: 87161.80\n",
      "Mean Absolute Error: 41856.48\n",
      "-----------------------\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "xgb_model = XGBRegressor(learning_rate=0.1, n_estimators=100, max_depth=3, objective='reg:squarederror')\n",
    "gb_model = GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "xgb_model.fit(X_train, y_train)\n",
    "gb_model.fit(X_train, y_train)\n",
    "rf_predictions = rf_model.predict(X_val)\n",
    "xgb_predictions = xgb_model.predict(X_val)\n",
    "gb_predictions = gb_model.predict(X_val)\n",
    "meta_model = LinearRegression()\n",
    "meta_features = pd.DataFrame({'RandomForest': rf_predictions, 'XGBoost': xgb_predictions, 'GradientBoosting': gb_predictions})\n",
    "meta_model.fit(meta_features, y_val)\n",
    "rf_test_predictions = rf_model.predict(X_test)\n",
    "xgb_test_predictions = xgb_model.predict(X_test)\n",
    "gb_test_predictions = gb_model.predict(X_test)\n",
    "meta_test_features = pd.DataFrame({'RandomForest': rf_test_predictions, 'XGBoost': xgb_test_predictions, 'GradientBoosting': gb_test_predictions})\n",
    "final_predictions = meta_model.predict(meta_test_features)\n",
    "ensemble_r2 = r2_score(y_test, final_predictions)\n",
    "ensemble_rmse = mean_squared_error(y_test, final_predictions, squared=False)\n",
    "ensemble_mae = mean_absolute_error(y_test, final_predictions)\n",
    "print(\"Ensemble Model Performance Metrics\")\n",
    "print(\"-----------------------\")\n",
    "print(f\"R-squared: {ensemble_r2:.2f}\")\n",
    "print(f\"Root Mean Squared Error: {ensemble_rmse:.2f}\")\n",
    "print(f\"Mean Absolute Error: {ensemble_mae:.2f}\")\n",
    "print(\"-----------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8adeb377-2c0e-4cbe-8106-05857b8eebb5",
   "metadata": {},
   "source": [
    "## Blending method for ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0b8501ea-4f76-465e-9520-9cfba9863b14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble Model Performance Metrics\n",
      "-----------------------\n",
      "R-squared: 0.74\n",
      "Root Mean Squared Error: 88480.09\n",
      "Mean Absolute Error: 42442.15\n",
      "-----------------------\n"
     ]
    }
   ],
   "source": [
    "X_base_train, X_meta_train, y_base_train, y_meta_train = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "rf_model.fit(X_base_train, y_base_train)\n",
    "xgb_model.fit(X_base_train, y_base_train)\n",
    "gb_model.fit(X_base_train, y_base_train)\n",
    "rf_meta_predictions = rf_model.predict(X_meta_train)\n",
    "xgb_meta_predictions = xgb_model.predict(X_meta_train)\n",
    "gb_meta_predictions = gb_model.predict(X_meta_train)\n",
    "meta_features = pd.DataFrame({'RandomForest': rf_meta_predictions, 'XGBoost': xgb_meta_predictions, 'GradientBoosting': gb_meta_predictions})\n",
    "meta_model.fit(meta_features, y_meta_train)\n",
    "rf_test_predictions = rf_model.predict(X_test)\n",
    "xgb_test_predictions = xgb_model.predict(X_test)\n",
    "gb_test_predictions = gb_model.predict(X_test)\n",
    "meta_test_features = pd.DataFrame({'RandomForest': rf_test_predictions, 'XGBoost': xgb_test_predictions, 'GradientBoosting': gb_test_predictions})\n",
    "final_predictions = meta_model.predict(meta_test_features)\n",
    "ensemble_r2 = r2_score(y_test, final_predictions)\n",
    "ensemble_rmse = mean_squared_error(y_test, final_predictions, squared=False)\n",
    "ensemble_mae = mean_absolute_error(y_test, final_predictions)\n",
    "print(\"Ensemble Model Performance Metrics\")\n",
    "print(\"-----------------------\")\n",
    "print(f\"R-squared: {ensemble_r2:.2f}\")\n",
    "print(f\"Root Mean Squared Error: {ensemble_rmse:.2f}\")\n",
    "print(f\"Mean Absolute Error: {ensemble_mae:.2f}\")\n",
    "print(\"-----------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ef340b6-b678-4b09-a35d-7c7fb296a4ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9f83d310-90e6-48b0-8088-dbc51a4582fb",
   "metadata": {},
   "source": [
    "## neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9d20addb-8bb9-4998-af50-223421c08d23",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "178/178 [==============================] - 0s 2ms/step\n",
      "Neural Network Performance Metrics\n",
      "-----------------------\n",
      "R-squared: 0.49\n",
      "Root Mean Squared Error: 125015.13\n",
      "Mean Absolute Error: 67906.16\n",
      "-----------------------\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "data = frames\n",
    "X = data.drop(columns=['price'])\n",
    "y = data['price']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "model = keras.Sequential([\n",
    "    layers.Input(shape=(X_train_scaled.shape[1],)), \n",
    "    layers.Dense(128, activation='relu'),  \n",
    "    layers.Dense(64, activation='relu'),   \n",
    "    layers.Dense(1) \n",
    "])\n",
    "model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])\n",
    "model.fit(X_train_scaled, y_train, epochs=100, batch_size=32, verbose=0)\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "print(\"Neural Network Performance Metrics\")\n",
    "print(\"-----------------------\")\n",
    "print(f\"R-squared: {r2:.2f}\")\n",
    "print(f\"Root Mean Squared Error: {rmse:.2f}\")\n",
    "print(f\"Mean Absolute Error: {mae:.2f}\")\n",
    "print(\"-----------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3a01fae9-06a7-4150-b138-e1f7c4e6a150",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "178/178 [==============================] - 0s 1ms/step\n",
      "Improved Neural Network Performance Metrics\n",
      "-----------------------\n",
      "R-squared: 0.45\n",
      "Root Mean Squared Error: 129786.08\n",
      "Mean Absolute Error: 79261.65\n",
      "-----------------------\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "data = frames\n",
    "X = data.drop(columns=['price'])\n",
    "y = data['price']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "model = keras.Sequential([\n",
    "    layers.Input(shape=(X_train_scaled.shape[1],)),\n",
    "    layers.Dense(256, activation='relu'),\n",
    "    layers.Dropout(0.2),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(1)\n",
    "])\n",
    "lr_schedule = keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate=0.01,\n",
    "    decay_steps=1000,\n",
    "    decay_rate=0.9\n",
    ")\n",
    "optimizer = keras.optimizers.Adam(learning_rate=lr_schedule)\n",
    "def custom_loss(y_true, y_pred):\n",
    "    return keras.losses.mean_squared_error(y_true, y_pred) + 0.01 * keras.losses.kl_divergence(y_true, y_pred)\n",
    "model.compile(optimizer=optimizer, loss=custom_loss, metrics=['mae'])\n",
    "early_stopping = keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "history = model.fit(\n",
    "    X_train_scaled, y_train, \n",
    "    epochs=150, \n",
    "    batch_size=64, \n",
    "    validation_data=(X_test_scaled, y_test), \n",
    "    verbose=0, \n",
    "    callbacks=[early_stopping]\n",
    ")\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "print(\"Improved Neural Network Performance Metrics\")\n",
    "print(\"-----------------------\")\n",
    "print(f\"R-squared: {r2:.2f}\")\n",
    "print(f\"Root Mean Squared Error: {rmse:.2f}\")\n",
    "print(f\"Mean Absolute Error: {mae:.2f}\")\n",
    "print(\"-----------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4eaa5ce3-c8b5-4ebe-a9e4-ebcf0b7a854d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "178/178 [==============================] - 0s 1ms/step\n",
      "Improved Neural Network Performance Metrics\n",
      "-----------------------\n",
      "R-squared: 0.59\n",
      "Root Mean Squared Error: 111911.90\n",
      "Mean Absolute Error: 60077.42\n",
      "-----------------------\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "data = frames\n",
    "X = data.drop(columns=['price'])\n",
    "y = data['price']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "model = keras.Sequential([\n",
    "    layers.Input(shape=(X_train_scaled.shape[1],)),\n",
    "    layers.Dense(256, activation='relu'),\n",
    "    layers.Dropout(0.3),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(32, activation='relu'),\n",
    "    layers.Dense(1)\n",
    "])\n",
    "initial_learning_rate = 0.01\n",
    "lr_schedule = keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate, decay_steps=1000, decay_rate=0.9, staircase=True\n",
    ")\n",
    "optimizer = keras.optimizers.Adam(learning_rate=lr_schedule)\n",
    "def custom_loss(y_true, y_pred):\n",
    "    mse = keras.losses.mean_squared_error(y_true, y_pred)\n",
    "    regularization = 0.01 * tf.reduce_sum(model.losses)\n",
    "    return mse + regularization\n",
    "\n",
    "model.compile(optimizer=optimizer, loss=custom_loss, metrics=['mae'])\n",
    "early_stopping = keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss', patience=15, restore_best_weights=True\n",
    ")\n",
    "history = model.fit(\n",
    "    X_train_scaled, y_train,\n",
    "    epochs=200,\n",
    "    batch_size=64,\n",
    "    validation_data=(X_test_scaled, y_test),\n",
    "    verbose=0,\n",
    "    callbacks=[early_stopping]\n",
    ")\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "print(\"Improved Neural Network Performance Metrics\")\n",
    "print(\"-----------------------\")\n",
    "print(f\"R-squared: {r2:.2f}\")\n",
    "print(f\"Root Mean Squared Error: {rmse:.2f}\")\n",
    "print(f\"Mean Absolute Error: {mae:.2f}\")\n",
    "print(\"-----------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9b709a64-80e8-4199-a410-4e4c87f14eb4",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "178/178 [==============================] - 0s 1ms/step\n",
      "178/178 [==============================] - 0s 2ms/step\n",
      "178/178 [==============================] - 0s 1ms/step\n",
      "178/178 [==============================] - 0s 2ms/step\n",
      "178/178 [==============================] - 0s 1ms/step\n",
      "Ensemble of Neural Networks Performance Metrics\n",
      "-----------------------\n",
      "R-squared: 0.62\n",
      "Root Mean Squared Error: 108341.71\n",
      "Mean Absolute Error: 59353.70\n",
      "-----------------------\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "data = frames\n",
    "X = data.drop(columns=['price'])\n",
    "y = data['price']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "num_networks = 5\n",
    "ensemble_predictions = []\n",
    "for i in range(num_networks):\n",
    "    model = keras.Sequential([\n",
    "        layers.Input(shape=(X_train_scaled.shape[1],)),\n",
    "        layers.Dense(256, activation='relu'),\n",
    "        layers.Dropout(0.3),\n",
    "        layers.Dense(128, activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dense(64, activation='relu'),\n",
    "        layers.Dense(32, activation='relu'),\n",
    "        layers.Dense(1)\n",
    "    ])\n",
    "    initial_learning_rate = 0.01\n",
    "    lr_schedule = keras.optimizers.schedules.ExponentialDecay(\n",
    "        initial_learning_rate, decay_steps=1000, decay_rate=0.9, staircase=True\n",
    "    )\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=lr_schedule)\n",
    "    def custom_loss(y_true, y_pred):\n",
    "        mse = keras.losses.mean_squared_error(y_true, y_pred)\n",
    "        regularization = 0.01 * tf.reduce_sum(model.losses)\n",
    "        return mse + regularization\n",
    "    model.compile(optimizer=optimizer, loss=custom_loss, metrics=['mae'])\n",
    "    early_stopping = keras.callbacks.EarlyStopping(\n",
    "        monitor='val_loss', patience=15, restore_best_weights=True\n",
    "    )\n",
    "    history = model.fit(\n",
    "        X_train_scaled, y_train,\n",
    "        epochs=200,\n",
    "        batch_size=64,\n",
    "        validation_data=(X_test_scaled, y_test),\n",
    "        verbose=0,\n",
    "        callbacks=[early_stopping]\n",
    "    )\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "    ensemble_predictions.append(y_pred)\n",
    "ensemble_predictions = np.mean(ensemble_predictions, axis=0)\n",
    "r2 = r2_score(y_test, ensemble_predictions)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, ensemble_predictions))\n",
    "mae = mean_absolute_error(y_test, ensemble_predictions)\n",
    "print(\"Ensemble of Neural Networks Performance Metrics\")\n",
    "print(\"-----------------------\")\n",
    "print(f\"R-squared: {r2:.2f}\")\n",
    "print(f\"Root Mean Squared Error: {rmse:.2f}\")\n",
    "print(f\"Mean Absolute Error: {mae:.2f}\")\n",
    "print(\"-----------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "289bfca6-c11d-4283-a922-1ef1a5e900ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "178/178 [==============================] - 0s 1ms/step\n",
      "178/178 [==============================] - 0s 1ms/step\n",
      "178/178 [==============================] - 0s 1ms/step\n",
      "178/178 [==============================] - 0s 1ms/step\n",
      "178/178 [==============================] - 0s 2ms/step\n",
      "Ensemble of Neural Networks Performance Metrics\n",
      "-----------------------\n",
      "R-squared: 0.67\n",
      "Root Mean Squared Error: 100792.64\n",
      "Mean Absolute Error: 50511.93\n",
      "-----------------------\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "data = frames\n",
    "X = data.drop(columns=['price'])\n",
    "y = data['price']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "num_networks = 5\n",
    "ensemble_predictions = []\n",
    "for i in range(num_networks):\n",
    "    model = keras.Sequential([\n",
    "        layers.Input(shape=(X_train_scaled.shape[1],)),\n",
    "        layers.Dense(512, activation='relu'),\n",
    "        layers.Dropout(0.3),\n",
    "        layers.Dense(256, activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dense(128, activation='relu'),\n",
    "        layers.Dense(64, activation='relu'),\n",
    "        layers.Dense(32, activation='relu'),\n",
    "        layers.Dense(1)\n",
    "    ])\n",
    "    initial_learning_rate = 0.01\n",
    "    lr_schedule = keras.optimizers.schedules.ExponentialDecay(\n",
    "        initial_learning_rate, decay_steps=1000, decay_rate=0.9, staircase=True\n",
    "    )\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=lr_schedule)\n",
    "    def custom_loss(y_true, y_pred):\n",
    "        mse = keras.losses.mean_squared_error(y_true, y_pred)\n",
    "        regularization = 0.01 * tf.reduce_sum(model.losses)\n",
    "        return mse + regularization\n",
    "    model.compile(optimizer=optimizer, loss=custom_loss, metrics=['mae'])\n",
    "    early_stopping = keras.callbacks.EarlyStopping(\n",
    "        monitor='val_loss', patience=15, restore_best_weights=True\n",
    "    )\n",
    "    history = model.fit(\n",
    "        X_train_scaled, y_train,\n",
    "        epochs=200,\n",
    "        batch_size=64,\n",
    "        validation_data=(X_test_scaled, y_test),\n",
    "        verbose=0,\n",
    "        callbacks=[early_stopping]\n",
    "    )\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "    ensemble_predictions.append(y_pred)\n",
    "ensemble_predictions = np.mean(ensemble_predictions, axis=0)\n",
    "r2 = r2_score(y_test, ensemble_predictions)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, ensemble_predictions))\n",
    "mae = mean_absolute_error(y_test, ensemble_predictions)\n",
    "print(\"Ensemble of Neural Networks Performance Metrics\")\n",
    "print(\"-----------------------\")\n",
    "print(f\"R-squared: {r2:.2f}\")\n",
    "print(f\"Root Mean Squared Error: {rmse:.2f}\")\n",
    "print(f\"Mean Absolute Error: {mae:.2f}\")\n",
    "print(\"-----------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "18cbdd54-7626-4f95-a4c6-57028b6d201b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "178/178 [==============================] - 0s 2ms/step\n",
      "178/178 [==============================] - 0s 1ms/step\n",
      "178/178 [==============================] - 0s 1ms/step\n",
      "178/178 [==============================] - 0s 1ms/step\n",
      "178/178 [==============================] - 0s 1ms/step\n",
      "178/178 [==============================] - 0s 1ms/step\n",
      "178/178 [==============================] - 0s 2ms/step\n",
      "178/178 [==============================] - 0s 1ms/step\n",
      "178/178 [==============================] - 0s 2ms/step\n",
      "178/178 [==============================] - 0s 2ms/step\n",
      "178/178 [==============================] - 1s 2ms/step\n",
      "178/178 [==============================] - 0s 1ms/step\n",
      "178/178 [==============================] - 0s 1ms/step\n",
      "178/178 [==============================] - 0s 1ms/step\n",
      "178/178 [==============================] - 0s 1ms/step\n",
      "178/178 [==============================] - 0s 1ms/step\n",
      "178/178 [==============================] - 0s 1ms/step\n",
      "178/178 [==============================] - 0s 2ms/step\n",
      "178/178 [==============================] - 0s 1ms/step\n",
      "178/178 [==============================] - 0s 2ms/step\n",
      "Ensemble of Neural Networks Performance Metrics\n",
      "-----------------------\n",
      "R-squared: 0.68\n",
      "Root Mean Squared Error: 99066.72\n",
      "Mean Absolute Error: 48012.44\n",
      "-----------------------\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "data = frames\n",
    "X = data.drop(columns=['price'])\n",
    "y = data['price']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "num_networks = 20\n",
    "ensemble_predictions = []\n",
    "for i in range(num_networks):\n",
    "    model = keras.Sequential([\n",
    "        layers.Input(shape=(X_train_scaled.shape[1],)),\n",
    "        layers.Dense(512, activation='relu'),\n",
    "        layers.Dropout(0.4),\n",
    "        layers.Dense(256, activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dense(128, activation='relu'),\n",
    "        layers.Dense(64, activation='relu'),\n",
    "        layers.Dense(32, activation='relu'),\n",
    "        layers.Dense(1)\n",
    "    ])\n",
    "    initial_learning_rate = 0.01\n",
    "    lr_schedule = keras.optimizers.schedules.ExponentialDecay(\n",
    "        initial_learning_rate, decay_steps=1000, decay_rate=0.9, staircase=True\n",
    "    )\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=lr_schedule)\n",
    "    def custom_loss(y_true, y_pred):\n",
    "        mse = keras.losses.mean_squared_error(y_true, y_pred)\n",
    "        regularization = 0.01 * tf.reduce_sum(model.losses)\n",
    "        return mse + regularization\n",
    "    model.compile(optimizer=optimizer, loss=custom_loss, metrics=['mae'])\n",
    "    early_stopping = keras.callbacks.EarlyStopping(\n",
    "        monitor='val_loss', patience=20, restore_best_weights=True\n",
    "    )\n",
    "    history = model.fit(\n",
    "        X_train_scaled, y_train,\n",
    "        epochs=250,\n",
    "        batch_size=64,\n",
    "        validation_data=(X_test_scaled, y_test),\n",
    "        verbose=0,\n",
    "        callbacks=[early_stopping]\n",
    "    )\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "    ensemble_predictions.append(y_pred)\n",
    "ensemble_predictions = np.mean(ensemble_predictions, axis=0)\n",
    "r2 = r2_score(y_test, ensemble_predictions)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, ensemble_predictions))\n",
    "mae = mean_absolute_error(y_test, ensemble_predictions)\n",
    "print(\"Ensemble of Neural Networks Performance Metrics\")\n",
    "print(\"-----------------------\")\n",
    "print(f\"R-squared: {r2:.2f}\")\n",
    "print(f\"Root Mean Squared Error: {rmse:.2f}\")\n",
    "print(f\"Mean Absolute Error: {mae:.2f}\")\n",
    "print(\"-----------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc7c255e-c5e9-46b4-aea5-9eb04cab2de6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
